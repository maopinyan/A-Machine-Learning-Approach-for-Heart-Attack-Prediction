{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mFf13fS6U32w",
    "outputId": "9cb5ae00-0ea9-460f-fda5-bb26a7cfbce6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljKvTNe8VSm4"
   },
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wI48pc7-VSrB",
    "outputId": "7dd81403-dac9-4fe7-f1de-bb769e056076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-26 06:48:04--  https://dlcdn.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz\n",
      "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
      "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 220400553 (210M) [application/x-gzip]\n",
      "Saving to: ‘spark-3.0.3-bin-hadoop2.7.tgz.1’\n",
      "\n",
      "spark-3.0.3-bin-had 100%[===================>] 210.19M   125MB/s    in 1.7s    \n",
      "\n",
      "2022-05-26 06:48:05 (125 MB/s) - ‘spark-3.0.3-bin-hadoop2.7.tgz.1’ saved [220400553/220400553]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://dlcdn.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OspBfqlCVSuN",
    "outputId": "699a8c06-4b1f-42c3-b5de-34c745caf63e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-3.0.3-bin-hadoop2.7/\n",
      "spark-3.0.3-bin-hadoop2.7/NOTICE\n",
      "spark-3.0.3-bin-hadoop2.7/kubernetes/\n",
      "spark-3.0.3-bin-hadoop2.7/kubernetes/tests/\n",
      "spark-3.0.3-bin-hadoop2.7/kubernetes/tests/worker_memory_check.py\n",
      "spark-3.0.3-bin-hadoop2.7/kubernetes/tests/py_container_checks.py\n",
      "spark-3.0.3-bin-hadoop2.7/kubernetes/tests/pyfiles.py\n",
      "spark-3.0.3-bin-hadoop2.7/kubernetes/dockerfiles/\n",
      "spark-3.0.3-bin-hadoop2.7/kubernetes/dockerfiles/spark/\n",
      "spark-3.0.3-bin-hadoop2.7/kubernetes/dockerfiles/spark/entrypoint.sh\n",
      "spark-3.0.3-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/\n",
      "spark-3.0.3-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/\n",
      "spark-3.0.3-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
      "spark-3.0.3-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/\n",
      "spark-3.0.3-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
      "spark-3.0.3-bin-hadoop2.7/kubernetes/dockerfiles/spark/Dockerfile\n",
      "spark-3.0.3-bin-hadoop2.7/jars/\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jackson-xc-1.9.13.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-digester-1.8.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/api-util-1.0.0-M20.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hive-vector-code-gen-2.3.7.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/derby-10.12.1.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-beanutils-1.9.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/httpcore-4.4.12.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hadoop-yarn-api-2.7.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/scala-library-2.12.10.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/parquet-format-2.4.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/kryo-shaded-4.0.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/xercesImpl-2.12.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-logging-1.1.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/okio-1.15.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-compiler-3.0.16.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jdo-api-3.0.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spire-macros_2.12-0.17.0-M1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/arrow-memory-0.15.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/JLargeArrays-1.5.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jsp-api-2.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/logging-interceptor-3.12.6.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/javax.servlet-api-3.1.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jcl-over-slf4j-1.7.30.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hive-cli-2.3.7.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/apacheds-i18n-2.0.0-M15.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/parquet-common-1.10.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/stax-api-1.0.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jackson-dataformat-yaml-2.10.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/algebra_2.12-2.0.0-M2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-graphx_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hadoop-annotations-2.7.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/guice-servlet-3.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/kubernetes-client-4.9.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spire-util_2.12-0.17.0-M1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jakarta.activation-api-1.2.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-network-shuffle_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jline-2.14.6.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/breeze_2.12-1.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/metrics-jvm-4.1.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-launcher_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/machinist_2.12-0.6.8.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/scala-compiler-2.12.10.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-pool-1.5.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/arrow-format-0.15.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-mllib_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jta-1.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-yarn_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/istack-commons-runtime-3.0.8.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/metrics-graphite-4.1.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hadoop-hdfs-2.7.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-collections-3.2.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/audience-annotations-0.5.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jpam-1.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jakarta.annotation-api-1.3.5.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/xmlenc-0.52.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/api-asn1-api-1.0.0-M20.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/py4j-0.10.9.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hadoop-mapreduce-client-common-2.7.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spire-platform_2.12-0.17.0-M1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/avro-1.8.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-core_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/curator-client-2.7.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/antlr4-runtime-4.7.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/javax.inject-1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-kubernetes_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jersey-media-jaxb-2.30.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-lang3-3.9.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/javax.jdo-3.2.0-m3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hadoop-auth-2.7.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-io-2.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/objenesis-2.5.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/paranamer-2.8.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/cats-kernel_2.12-2.0.0-M4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/flatbuffers-java-1.9.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jersey-server-2.30.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/stream-2.9.6.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/datanucleus-api-jdo-4.2.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/gson-2.2.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/xml-apis-1.4.01.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/apacheds-kerberos-codec-2.0.0-M15.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hadoop-mapreduce-client-shuffle-2.7.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-hive_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hive-jdbc-2.3.7.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hive-exec-2.3.7-core.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/opencsv-2.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-sketch_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/avro-mapred-1.8.2-hadoop2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jsr305-3.0.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/univocity-parsers-2.9.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/macro-compat_2.12-1.1.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-dbcp-1.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jersey-container-servlet-core-2.30.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/orc-core-1.5.10.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hk2-api-2.6.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/parquet-jackson-1.10.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/mesos-1.4.0-shaded-protobuf.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/chill-java-0.9.5.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-tags_2.12-3.0.3-tests.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/automaton-1.11-8.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-lang-2.6.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jackson-annotations-2.10.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hk2-utils-2.6.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-network-common_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-repl_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/velocity-1.5.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/htrace-core-3.1.0-incubating.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jul-to-slf4j-1.7.30.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/JTransforms-3.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/json4s-ast_2.12-3.6.6.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jersey-client-2.30.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/httpclient-4.5.6.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jetty-sslengine-6.1.26.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-kvstore_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spire_2.12-0.17.0-M1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jersey-hk2-2.30.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-math3-3.4.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/xbean-asm7-shaded-4.15.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jakarta.validation-api-2.0.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/parquet-encoding-1.10.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/snappy-java-1.1.8.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/slf4j-log4j12-1.7.30.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hadoop-mapreduce-client-app-2.7.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/zstd-jni-1.4.4-3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/slf4j-api-1.7.30.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hive-shims-0.23-2.3.7.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/guava-14.0.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/stax-api-1.0-2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/zjsonpatch-0.3.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hive-storage-api-2.7.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/shapeless_2.12-2.3.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/kubernetes-model-common-4.9.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/oro-2.0.8.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hadoop-yarn-client-2.7.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/libfb303-0.9.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/core-1.1.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jersey-container-servlet-2.30.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/datanucleus-rdbms-4.1.19.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/super-csv-2.2.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/compress-lzf-1.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jackson-module-paranamer-2.10.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/aopalliance-1.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/osgi-resource-locator-1.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jackson-module-scala_2.12-2.10.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hive-shims-2.3.7.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hadoop-yarn-server-common-2.7.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/json-1.8.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/antlr-runtime-3.5.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/threeten-extra-1.5.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jetty-6.1.26.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-tags_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jackson-module-jaxb-annotations-2.10.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jersey-common-2.30.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/aircompressor-0.10.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/lz4-java-1.7.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hadoop-client-2.7.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/activation-1.1.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/shims-0.7.45.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-crypto-1.1.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-mesos_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/libthrift-0.12.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/orc-mapreduce-1.5.10.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/HikariCP-2.5.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/generex-1.0.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/okhttp-3.12.6.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/breeze-macros_2.12-1.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/leveldbjni-all-1.8.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jaxb-runtime-2.3.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-httpclient-3.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jackson-core-asl-1.9.13.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/scala-xml_2.12-1.2.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hk2-locator-2.6.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hadoop-common-2.7.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/curator-recipes-2.7.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jackson-mapper-asl-1.9.13.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hive-common-2.3.7.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/xz-1.5.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/ST4-4.0.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hive-shims-scheduler-2.3.7.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-unsafe_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/parquet-hadoop-1.10.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/chill_2.12-0.9.5.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-configuration-1.6.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jackson-databind-2.10.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-hive-thriftserver_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/scala-reflect-2.12.10.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/joda-time-2.10.5.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/minlog-1.3.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jakarta.ws.rs-api-2.1.6.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/orc-shims-1.5.10.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/aopalliance-repackaged-2.6.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-compress-1.20.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/bonecp-0.8.0.RELEASE.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jodd-core-3.5.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hadoop-yarn-server-web-proxy-2.7.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jackson-core-2.10.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/protobuf-java-2.5.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-net-3.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hadoop-mapreduce-client-jobclient-2.7.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/datanucleus-core-4.1.17.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jackson-jaxrs-1.9.13.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/janino-3.0.16.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hive-shims-common-2.3.7.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/javolution-5.5.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/transaction-api-1.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-streaming_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jackson-datatype-jsr310-2.10.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-mllib-local_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jaxb-api-2.2.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-cli-1.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jakarta.inject-2.6.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/metrics-jmx-4.1.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/arrow-vector-0.15.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jakarta.xml.bind-api-2.3.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-codec-1.10.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-catalyst_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hadoop-yarn-common-2.7.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/curator-framework-2.7.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/arpack_combined_all-0.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hive-metastore-2.3.7.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hive-beeline-2.3.7.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/metrics-core-4.1.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hive-llap-common-2.3.7.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/netty-all-4.1.47.Final.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/javassist-3.25.0-GA.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/scala-collection-compat_2.12-2.1.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/spark-sql_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/parquet-column-1.10.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/jetty-util-6.1.26.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/kubernetes-model-4.9.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/avro-ipc-1.8.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/guice-3.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/commons-text-1.6.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/json4s-scalap_2.12-3.6.6.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/metrics-json-4.1.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/snakeyaml-1.24.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/json4s-jackson_2.12-3.6.6.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/ivy-2.4.0.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hadoop-mapreduce-client-core-2.7.4.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/json4s-core_2.12-3.6.6.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/pyrolite-4.30.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/log4j-1.2.17.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/hive-serde-2.3.7.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/scala-parser-combinators_2.12-1.1.2.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/RoaringBitmap-0.7.45.jar\n",
      "spark-3.0.3-bin-hadoop2.7/jars/zookeeper-3.4.14.jar\n",
      "spark-3.0.3-bin-hadoop2.7/data/\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/sample_lda_data.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/sample_svm_data.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/sample_multiclass_classification_data.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/sample_linear_regression_data.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/sample_lda_libsvm_data.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/sample_fpgrowth.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/sample_binary_classification_data.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/iris_libsvm.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/sample_movielens_data.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/als/\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/als/test.data\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/als/sample_movielens_ratings.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/sample_kmeans_data.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/pic_data.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/origin/\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/origin/kittens/\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/origin/kittens/54893.jpg\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/origin/kittens/not-image.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/origin/kittens/DP802813.jpg\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/origin/kittens/DP153539.jpg\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/origin/license.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/origin/multi-channel/\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA.png\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/partitioned/\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/images/license.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/ridge-data/\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/ridge-data/lpsa.data\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/kmeans_data.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/streaming_kmeans_data_test.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/pagerank_data.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/mllib/gmm_data.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/graphx/\n",
      "spark-3.0.3-bin-hadoop2.7/data/graphx/users.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/graphx/followers.txt\n",
      "spark-3.0.3-bin-hadoop2.7/data/streaming/\n",
      "spark-3.0.3-bin-hadoop2.7/data/streaming/AFINN-111.txt\n",
      "spark-3.0.3-bin-hadoop2.7/R/\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/sparkr.zip\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/tests/\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/tests/testthat/\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/tests/testthat/test_basic.R\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/DESCRIPTION\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/profile/\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/profile/shell.R\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/profile/general.R\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/INDEX\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/Meta/\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/Meta/features.rds\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/Meta/links.rds\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/Meta/nsInfo.rds\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/Meta/package.rds\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/Meta/Rd.rds\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/Meta/hsearch.rds\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/help/\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdb\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/help/aliases.rds\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdx\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/help/AnIndex\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/help/paths.rds\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/R/\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdb\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdx\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/R/SparkR\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/NAMESPACE\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/html/\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/html/00Index.html\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/html/R.css\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/worker/\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/worker/worker.R\n",
      "spark-3.0.3-bin-hadoop2.7/R/lib/SparkR/worker/daemon.R\n",
      "spark-3.0.3-bin-hadoop2.7/README.md\n",
      "spark-3.0.3-bin-hadoop2.7/RELEASE\n",
      "spark-3.0.3-bin-hadoop2.7/yarn/\n",
      "spark-3.0.3-bin-hadoop2.7/yarn/spark-3.0.3-yarn-shuffle.jar\n",
      "spark-3.0.3-bin-hadoop2.7/LICENSE\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/stop-mesos-shuffle-service.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/start-master.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/spark-config.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/start-history-server.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/start-slaves.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/spark-daemon.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/stop-mesos-dispatcher.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/start-mesos-shuffle-service.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/slaves.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/stop-history-server.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/start-thriftserver.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/stop-thriftserver.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/start-slave.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/start-all.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/stop-slave.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/spark-daemons.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/stop-slaves.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/stop-all.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/start-mesos-dispatcher.sh\n",
      "spark-3.0.3-bin-hadoop2.7/sbin/stop-master.sh\n",
      "spark-3.0.3-bin-hadoop2.7/examples/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/survreg.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/glm.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/prefixSpan.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/powerIterationClustering.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/lda.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/kstest.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/isoreg.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/ml.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/naiveBayes.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/mlp.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/als.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/kmeans.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/svmLinear.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/logit.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/randomForest.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/gbt.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/decisionTree.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/gaussianMixture.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/bisectingKmeans.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/ml/fpm.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/dataframe.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/RSparkSQLExample.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/data-manipulation.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/streaming/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/r/streaming/structured_network_wordcount.R\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/resources/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/resources/people.json\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/resources/users.avro\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/resources/people.csv\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/resources/users.parquet\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/resources/users.orc\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/resources/dir1/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/resources/dir1/file1.parquet\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/resources/dir1/dir2/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/resources/dir1/dir2/file2.parquet\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/resources/dir1/file3.json\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/resources/user.avsc\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/resources/full_user.avsc\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/resources/kv1.txt\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/resources/people.txt\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/resources/employees.json\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scripts/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/scripts/getGpusResources.sh\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/kmeans.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/dct_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/count_vectorizer_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/chisq_selector_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/tf_idf_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/cross_validator.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/normalizer_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/fm_regressor_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/polynomial_expansion_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/pipeline_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/bisecting_k_means_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/chi_square_test_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/train_validation_split.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/stopwords_remover_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/linearsvc.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/lda_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/random_forest_regressor_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/vector_assembler_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/word2vec_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/string_indexer_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_classification_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/index_to_string_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/bucketizer_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/vector_size_hint_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/vector_indexer_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/tokenizer_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/robust_scaler_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/standard_scaler_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/kmeans_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/naive_bayes_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/pca_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/aft_survival_regression.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/min_max_scaler_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/elementwise_product_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/dataframe_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/n_gram_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/rformula_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/one_vs_rest_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/als_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/onehot_encoder_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/vector_slicer_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/sql_transformer.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/summarizer_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/quantile_discretizer_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/feature_hasher_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/imputer_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_regression_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/fm_classifier_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/gaussian_mixture_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/fpgrowth_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/random_forest_classifier_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/correlation_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/min_hash_lsh_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/binarizer_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/prefixspan_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/max_abs_scaler_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/isotonic_regression_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/ml/interaction_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/logistic_regression.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/als.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/word2vec.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/correlations_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/svd_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/kmeans.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/tf_idf_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/correlations.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_regression_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/normalizer_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_classification_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/sampled_rdds.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/k_means_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/streaming_k_means_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/word2vec_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/summary_statistics_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/standard_scaler_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/regression_metrics_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/naive_bayes_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/elementwise_product_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/random_rdd_generation.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/recommendation_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/fpgrowth_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/ranking_metrics_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/isotonic_regression_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/mllib/stratified_sampling_example.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/wordcount.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/status_api_demo.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/pagerank.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/sort.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/transitive_closure.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/avro_inputformat.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/pi.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/streaming/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/streaming/queue_stream.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/streaming/sql_network_wordcount.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/streaming/network_wordcount.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/streaming/hdfs_wordcount.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/sql/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/sql/datasource.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/sql/hive.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/sql/arrow.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/sql/streaming/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/sql/basic.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/src/main/python/parquet_inputformat.py\n",
      "spark-3.0.3-bin-hadoop2.7/examples/jars/\n",
      "spark-3.0.3-bin-hadoop2.7/examples/jars/spark-examples_2.12-3.0.3.jar\n",
      "spark-3.0.3-bin-hadoop2.7/examples/jars/scopt_2.12-3.7.1.jar\n",
      "spark-3.0.3-bin-hadoop2.7/conf/\n",
      "spark-3.0.3-bin-hadoop2.7/conf/slaves.template\n",
      "spark-3.0.3-bin-hadoop2.7/conf/metrics.properties.template\n",
      "spark-3.0.3-bin-hadoop2.7/conf/fairscheduler.xml.template\n",
      "spark-3.0.3-bin-hadoop2.7/conf/log4j.properties.template\n",
      "spark-3.0.3-bin-hadoop2.7/conf/spark-defaults.conf.template\n",
      "spark-3.0.3-bin-hadoop2.7/conf/spark-env.sh.template\n",
      "spark-3.0.3-bin-hadoop2.7/bin/\n",
      "spark-3.0.3-bin-hadoop2.7/bin/sparkR.cmd\n",
      "spark-3.0.3-bin-hadoop2.7/bin/sparkR\n",
      "spark-3.0.3-bin-hadoop2.7/bin/spark-submit\n",
      "spark-3.0.3-bin-hadoop2.7/bin/pyspark2.cmd\n",
      "spark-3.0.3-bin-hadoop2.7/bin/spark-class\n",
      "spark-3.0.3-bin-hadoop2.7/bin/pyspark.cmd\n",
      "spark-3.0.3-bin-hadoop2.7/bin/spark-submit2.cmd\n",
      "spark-3.0.3-bin-hadoop2.7/bin/load-spark-env.cmd\n",
      "spark-3.0.3-bin-hadoop2.7/bin/spark-sql\n",
      "spark-3.0.3-bin-hadoop2.7/bin/docker-image-tool.sh\n",
      "spark-3.0.3-bin-hadoop2.7/bin/find-spark-home.cmd\n",
      "spark-3.0.3-bin-hadoop2.7/bin/load-spark-env.sh\n",
      "spark-3.0.3-bin-hadoop2.7/bin/pyspark\n",
      "spark-3.0.3-bin-hadoop2.7/bin/spark-shell.cmd\n",
      "spark-3.0.3-bin-hadoop2.7/bin/spark-shell2.cmd\n",
      "spark-3.0.3-bin-hadoop2.7/bin/spark-submit.cmd\n",
      "spark-3.0.3-bin-hadoop2.7/bin/beeline.cmd\n",
      "spark-3.0.3-bin-hadoop2.7/bin/find-spark-home\n",
      "spark-3.0.3-bin-hadoop2.7/bin/spark-class.cmd\n",
      "spark-3.0.3-bin-hadoop2.7/bin/sparkR2.cmd\n",
      "spark-3.0.3-bin-hadoop2.7/bin/beeline\n",
      "spark-3.0.3-bin-hadoop2.7/bin/spark-class2.cmd\n",
      "spark-3.0.3-bin-hadoop2.7/bin/spark-sql.cmd\n",
      "spark-3.0.3-bin-hadoop2.7/bin/run-example\n",
      "spark-3.0.3-bin-hadoop2.7/bin/spark-shell\n",
      "spark-3.0.3-bin-hadoop2.7/bin/run-example.cmd\n",
      "spark-3.0.3-bin-hadoop2.7/bin/spark-sql2.cmd\n",
      "spark-3.0.3-bin-hadoop2.7/python/\n",
      "spark-3.0.3-bin-hadoop2.7/python/.gitignore\n",
      "spark-3.0.3-bin-hadoop2.7/python/run-tests-with-coverage\n",
      "spark-3.0.3-bin-hadoop2.7/python/pylintrc\n",
      "spark-3.0.3-bin-hadoop2.7/python/MANIFEST.in\n",
      "spark-3.0.3-bin-hadoop2.7/python/README.md\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_coverage/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_coverage/coverage_daemon.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_coverage/conf/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_coverage/conf/spark-defaults.conf\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_coverage/sitecustomize.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/run-tests.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/setup.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/userlibrary.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/hello/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/hello/sub_hello/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/hello/sub_hello/sub_hello.txt\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/hello/hello.txt\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/userlib-0.1.zip\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/SimpleHTTPServer.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/people.json\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/people_array.json\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/people_array_utf16le.json\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/text-test.txt\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/ages.csv\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_metadata\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_common_metadata\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/_SUCCESS\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/ages_newlines.csv\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/streaming/\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/streaming/text-test.txt\n",
      "spark-3.0.3-bin-hadoop2.7/python/test_support/sql/people1.json\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/test_rddbarrier.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/test_worker.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/test_serializers.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/test_util.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/test_rdd.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/__init__.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/test_broadcast.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/test_appsubmit.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/test_profiler.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/test_pin_thread.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/test_shuffle.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/test_join.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/test_taskcontext.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/test_context.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/test_readwrite.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/test_conf.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/tests/test_daemon.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/testing/\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/testing/mlutils.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/testing/__init__.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/testing/mllibutils.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/testing/utils.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/testing/sqlutils.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/testing/streamingutils.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/accumulators.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/rddsampler.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tests/\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tests/test_algorithms.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tests/test_evaluation.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tests/test_util.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tests/test_feature.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tests/test_pipeline.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tests/test_wrapper.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tests/__init__.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tests/test_tuning.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tests/test_persistence.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tests/test_param.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tests/test_training_summary.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tests/test_linalg.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tests/test_image.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tests/test_stat.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tests/test_base.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/functions.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tuning.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/pipeline.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/base.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/feature.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/__init__.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/stat.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/image.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/classification.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/recommendation.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/regression.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/param/\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/param/__init__.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/param/shared.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/tree.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/fpm.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/wrapper.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/clustering.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/common.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/linalg/\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/evaluation.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/ml/util.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/find_spark_home.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/heapq3.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/serializers.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/java_gateway.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/traceback_utils.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/conf.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/__init__.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/tests/\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/tests/test_algorithms.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/tests/test_util.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/tests/test_feature.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/tests/__init__.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/tests/test_linalg.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/tests/test_stat.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/feature.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/__init__.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/classification.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/recommendation.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/regression.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/tree.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/fpm.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/random.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/stat/\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/stat/test.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/clustering.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/common.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/linalg/\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/evaluation.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/mllib/util.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/resultiterable.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/profiler.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/statcounter.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/join.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/daemon.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/rdd.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/context.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/cloudpickle.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/version.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/resource.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/files.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/worker.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/shell.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/streaming/\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/streaming/tests/\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/streaming/tests/test_listener.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/streaming/tests/test_kinesis.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/streaming/tests/__init__.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/streaming/tests/test_dstream.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/streaming/tests/test_context.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/streaming/dstream.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/streaming/__init__.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/streaming/kinesis.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/streaming/listener.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/streaming/context.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/streaming/util.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/status.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_functions.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_readwriter.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_utils.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_grouped_map.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_dataframe.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_map.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_udf.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_streaming.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/__init__.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_serde.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_window.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_group.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_cogrouped_map.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_catalog.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_datasources.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_typehints.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_types.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_column.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_context.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_conf.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_arrow.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/tests/test_session.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/pandas/\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/pandas/functions.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/pandas/serializers.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/pandas/__init__.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/pandas/typehints.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/pandas/map_ops.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/pandas/types.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/pandas/group_ops.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/pandas/utils.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/functions.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/readwriter.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/catalog.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/window.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/udf.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/conf.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/__init__.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/session.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/column.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/group.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/context.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/types.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/dataframe.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/avro/\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/avro/functions.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/avro/__init__.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/utils.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/streaming.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/shuffle.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/taskcontext.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/_globals.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/broadcast.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/util.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/pyspark/storagelevel.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/.coveragerc\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/index.rst\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/conf.py\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/pyspark.ml.rst\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/pyspark.rst\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/_templates/\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/_templates/layout.html\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/_static/\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/_static/pyspark.css\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/_static/copybutton.js\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/_static/pyspark.js\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/pyspark.mllib.rst\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/make2.bat\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/pyspark.streaming.rst\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/pyspark.sql.rst\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/make.bat\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/Makefile\n",
      "spark-3.0.3-bin-hadoop2.7/python/docs/pyspark.resource.rst\n",
      "spark-3.0.3-bin-hadoop2.7/python/lib/\n",
      "spark-3.0.3-bin-hadoop2.7/python/lib/PY4J_LICENSE.txt\n",
      "spark-3.0.3-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip\n",
      "spark-3.0.3-bin-hadoop2.7/python/lib/pyspark.zip\n",
      "spark-3.0.3-bin-hadoop2.7/python/run-tests\n",
      "spark-3.0.3-bin-hadoop2.7/python/setup.cfg\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-respond.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-sbt-launch-lib.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-antlr.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-dagre-d3.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-pyrolite.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-sorttable.js.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-janino.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-protobuf.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-jquery.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-scopt.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-netlib.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-d3.min.js.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-graphlib-dot.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-AnchorJS.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-datatables.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-pmml-model.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-paranamer.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-jakarta-ws-rs-api\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-dnsjava.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-jakarta-annotation-api\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-CC0.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-jodd.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-f2j.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-heapq.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-machinist.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-javolution.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-modernizr.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-spire.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-leveldbjni.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-join.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-zstd-jni.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-slf4j.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-arpack.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-jsp-api.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-JTransforms.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-JLargeArrays.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-bootstrap.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-reflectasm.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-javassist.html\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-zstd.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-json-formatter.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-matchMedia-polyfill.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-scala.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-jakarta.activation-api.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-automaton.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-jaxb-runtime.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-minlog.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-mustache.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-xmlenc.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-jline.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-istack-commons-runtime.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-py4j.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-vis-timeline.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-re2j.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-kryo.txt\n",
      "spark-3.0.3-bin-hadoop2.7/licenses/LICENSE-cloudpickle.txt\n"
     ]
    }
   ],
   "source": [
    "!tar xvf spark-3.0.3-bin-hadoop2.7.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMp-SyqcVSxB"
   },
   "outputs": [],
   "source": [
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJ-oGxHoVSzf",
    "outputId": "bce1ddab-bc16-41c9-f643-b4db230ad466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pyspark==3.0.3 in /usr/local/lib/python3.7/dist-packages (3.0.3)\n",
      "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark==3.0.3) (0.10.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark==3.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NGr8b_1_VS1-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"spark-3.0.3-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "id": "PjIaA1QJVS4J",
    "outputId": "e9e048be-d4ef-4b2c-8005-741e2f8eb41d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://7c3053d358ed:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>INFO607_Project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f73b50381d0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "APP_NAME = \"INFO607_Project\"\n",
    "spark = SparkSession.builder.appName(APP_NAME).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfGjh0Q3Vtn6"
   },
   "source": [
    "**Read dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kf0VchuptJBn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUuV-sDjVyun"
   },
   "outputs": [],
   "source": [
    "pathway ='/content/gdrive/MyDrive/INFO607_project/heart.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4crmBdfqVy6w",
    "outputId": "76e6bfe7-c1cb-4448-d5cf-ba4be2809388"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+----------------+----------------------+-----------+-------------------+----------------------------+------------------+-----------------------+-------+---+-----------------+-----+---------------------------+\n",
      "|_c0|age|sex|chestPain       |resting_blood_pressure|cholestoral|fasting_blood_sugar|resting_electrocardiographic|maximum_heart_rate|exercise_induced_angina|oldpeak|slp|number_of_vessels|thall|output                     |\n",
      "+---+---+---+----------------+----------------------+-----------+-------------------+----------------------------+------------------+-----------------------+-------+---+-----------------+-----+---------------------------+\n",
      "|0  |63 |1  |asymptomatic    |145                   |233        |true               |normal                      |150               |no                     |2.3    |0  |0                |1    |more chance of heart attact|\n",
      "|1  |37 |1  |non-anginal pain|130                   |250        |false              |having ST-T wave abnormality|187               |no                     |3.5    |0  |0                |2    |more chance of heart attact|\n",
      "|2  |41 |0  |atypical angina |130                   |204        |false              |normal                      |172               |no                     |1.4    |2  |0                |2    |more chance of heart attact|\n",
      "|3  |56 |1  |atypical angina |120                   |236        |false              |having ST-T wave abnormality|178               |no                     |0.8    |2  |0                |2    |more chance of heart attact|\n",
      "|4  |57 |0  |typical angina  |120                   |354        |false              |having ST-T wave abnormality|163               |yes                    |0.6    |2  |0                |2    |more chance of heart attact|\n",
      "+---+---+---+----------------+----------------------+-----------+-------------------+----------------------------+------------------+-----------------------+-------+---+-----------------+-----+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heart_df = spark.read.csv(pathway, header = True)\n",
    "heart_df.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jZogrbyVWcE8",
    "outputId": "19ddec96-b793-4cf8-a006-dfdca541863a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- chestPain: string (nullable = true)\n",
      " |-- resting_blood_pressure: string (nullable = true)\n",
      " |-- cholestoral: string (nullable = true)\n",
      " |-- fasting_blood_sugar: string (nullable = true)\n",
      " |-- resting_electrocardiographic: string (nullable = true)\n",
      " |-- maximum_heart_rate: string (nullable = true)\n",
      " |-- exercise_induced_angina: string (nullable = true)\n",
      " |-- oldpeak: string (nullable = true)\n",
      " |-- slp: string (nullable = true)\n",
      " |-- number_of_vessels: string (nullable = true)\n",
      " |-- thall: string (nullable = true)\n",
      " |-- output: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heart_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41QZrKQfO6uA"
   },
   "source": [
    "Changing column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQecBedNYypl"
   },
   "outputs": [],
   "source": [
    "heart_df = heart_df.withColumnRenamed('caa','number_of_vessels')\n",
    "heart_df = heart_df.withColumnRenamed('cp','chestPain')\n",
    "heart_df = heart_df.withColumnRenamed('trtbps', 'resting_blood_pressure')\n",
    "heart_df = heart_df.withColumnRenamed('restecg', 'resting_electrocardiographic')\n",
    "heart_df = heart_df.withColumnRenamed('thalachh','maximum_heart_rate')\n",
    "heart_df = heart_df.withColumnRenamed('chol','cholestoral')\n",
    "heart_df = heart_df.withColumnRenamed('exng','exercise_induced_angina')\n",
    "heart_df = heart_df.withColumnRenamed('fbs','fasting_blood_sugar')\n",
    "heart_df = heart_df.withColumnRenamed('slp','slope')\n",
    "heart_df = heart_df.withColumnRenamed('oldpeak','previous_peak')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_3k1zJD7Yyv0",
    "outputId": "1ed27fc1-ea93-4d6d-9777-730f81cae2ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+----------------+----------------------+-----------+-------------------+----------------------------+------------------+-----------------------+-------------+-----+-----------------+-----+--------------------+\n",
      "|_c0|age|sex|       chestPain|resting_blood_pressure|cholestoral|fasting_blood_sugar|resting_electrocardiographic|maximum_heart_rate|exercise_induced_angina|previous_peak|slope|number_of_vessels|thall|              output|\n",
      "+---+---+---+----------------+----------------------+-----------+-------------------+----------------------------+------------------+-----------------------+-------------+-----+-----------------+-----+--------------------+\n",
      "|  0| 63|  1|    asymptomatic|                   145|        233|               true|                      normal|               150|                     no|          2.3|    0|                0|    1|more chance of he...|\n",
      "|  1| 37|  1|non-anginal pain|                   130|        250|              false|        having ST-T wave ...|               187|                     no|          3.5|    0|                0|    2|more chance of he...|\n",
      "|  2| 41|  0| atypical angina|                   130|        204|              false|                      normal|               172|                     no|          1.4|    2|                0|    2|more chance of he...|\n",
      "|  3| 56|  1| atypical angina|                   120|        236|              false|        having ST-T wave ...|               178|                     no|          0.8|    2|                0|    2|more chance of he...|\n",
      "|  4| 57|  0|  typical angina|                   120|        354|              false|        having ST-T wave ...|               163|                    yes|          0.6|    2|                0|    2|more chance of he...|\n",
      "+---+---+---+----------------+----------------------+-----------+-------------------+----------------------------+------------------+-----------------------+-------------+-----+-----------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heart_df.show(5, truncate = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlccC-6oRxW2"
   },
   "source": [
    "Target variable: output. 0= less chance of heart attack, 1= more chance of heart attack. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "azAwxLiuYy2e",
    "outputId": "6c028910-363e-4bcb-84cb-353ed9a050a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|              output|count|\n",
      "+--------------------+-----+\n",
      "|less chance of he...|  138|\n",
      "|more chance of he...|  165|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To see the distribution of target variable.\n",
    "heart_df.groupBy('output').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hb8v1N6B_AQE",
    "outputId": "0b30905a-3893-4d37-ca7a-afb9e5b9a05b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|       chestPain|count|\n",
      "+----------------+-----+\n",
      "|    asymptomatic|   23|\n",
      "|non-anginal pain|   87|\n",
      "|  typical angina|  143|\n",
      "| atypical angina|   50|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heart_df.groupBy('chestPain').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RPIcWffF_g64",
    "outputId": "77d0fc60-87c7-484e-f211-c1149c554e09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|number_of_vessels|count|\n",
      "+-----------------+-----+\n",
      "|                3|   20|\n",
      "|                0|  175|\n",
      "|                1|   65|\n",
      "|                4|    5|\n",
      "|                2|   38|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heart_df.groupBy('number_of_vessels').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VLaz_Z7lFmCd",
    "outputId": "1fa752b0-8b3d-4baf-f452-5dcf4d5b088c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-----+\n",
      "|resting_electrocardiographic|count|\n",
      "+----------------------------+-----+\n",
      "|        left ventricular ...|    4|\n",
      "|                      normal|  147|\n",
      "|        having ST-T wave ...|  152|\n",
      "+----------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heart_df.groupBy('resting_electrocardiographic').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cj5SKdmhNQuf",
    "outputId": "57d881fe-1a94-45fd-ca18-9c267034aaf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "|  0|   96|\n",
      "|  1|  207|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heart_df.groupBy('sex').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_woqw768kEyV",
    "outputId": "dacd7da8-1499-46ed-bfd6-3989bb35cc0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------------+---------------------------+\n",
      "|sex_output|less chance of heart attact|more chance of heart attact|\n",
      "+----------+---------------------------+---------------------------+\n",
      "|         1|                        114|                         93|\n",
      "|         0|                         24|                         72|\n",
      "+----------+---------------------------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heart_df.crosstab('sex', 'output').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O62ki1V5IBO9"
   },
   "outputs": [],
   "source": [
    "heart = heart_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LmCMO28Fth-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "obLGaaV4I8I6",
    "outputId": "5b0093e3-bd06-4c0d-b647-c45f87b88048"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'count'), Text(0.5, 0, 'heart attack')]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,4))\n",
    "plt.title('chances of heart attack')\n",
    "ax = sns.countplot(x = 'output', data = heart)\n",
    "ax.set(xlabel = 'heart attack', ylabel = 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EreXee2XFurU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "c8v5khtTsIgY",
    "outputId": "d6d16a5c-a177-42b6-e09c-5c87c565283c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-51d48579-3d5f-46a5-b644-878cd5383319\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chestPain</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>cholestoral</th>\n",
       "      <th>fasting_blood_sugar</th>\n",
       "      <th>resting_electrocardiographic</th>\n",
       "      <th>maximum_heart_rate</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <th>previous_peak</th>\n",
       "      <th>slope</th>\n",
       "      <th>number_of_vessels</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>true</td>\n",
       "      <td>normal</td>\n",
       "      <td>150</td>\n",
       "      <td>no</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>more chance of heart attact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>non-anginal pain</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>false</td>\n",
       "      <td>having ST-T wave abnormality</td>\n",
       "      <td>187</td>\n",
       "      <td>no</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>more chance of heart attact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>false</td>\n",
       "      <td>normal</td>\n",
       "      <td>172</td>\n",
       "      <td>no</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>more chance of heart attact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>false</td>\n",
       "      <td>having ST-T wave abnormality</td>\n",
       "      <td>178</td>\n",
       "      <td>no</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>more chance of heart attact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>false</td>\n",
       "      <td>having ST-T wave abnormality</td>\n",
       "      <td>163</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>more chance of heart attact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51d48579-3d5f-46a5-b644-878cd5383319')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-51d48579-3d5f-46a5-b644-878cd5383319 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-51d48579-3d5f-46a5-b644-878cd5383319');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  _c0 age sex         chestPain resting_blood_pressure cholestoral  \\\n",
       "0   0  63   1      asymptomatic                    145         233   \n",
       "1   1  37   1  non-anginal pain                    130         250   \n",
       "2   2  41   0   atypical angina                    130         204   \n",
       "3   3  56   1   atypical angina                    120         236   \n",
       "4   4  57   0    typical angina                    120         354   \n",
       "\n",
       "  fasting_blood_sugar  resting_electrocardiographic maximum_heart_rate  \\\n",
       "0                true                        normal                150   \n",
       "1               false  having ST-T wave abnormality                187   \n",
       "2               false                        normal                172   \n",
       "3               false  having ST-T wave abnormality                178   \n",
       "4               false  having ST-T wave abnormality                163   \n",
       "\n",
       "  exercise_induced_angina previous_peak slope number_of_vessels thall  \\\n",
       "0                      no           2.3     0                 0     1   \n",
       "1                      no           3.5     0                 0     2   \n",
       "2                      no           1.4     2                 0     2   \n",
       "3                      no           0.8     2                 0     2   \n",
       "4                     yes           0.6     2                 0     2   \n",
       "\n",
       "                        output  \n",
       "0  more chance of heart attact  \n",
       "1  more chance of heart attact  \n",
       "2  more chance of heart attact  \n",
       "3  more chance of heart attact  \n",
       "4  more chance of heart attact  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMTZIr8Gu_lu"
   },
   "outputs": [],
   "source": [
    "heart.output.replace(['0', '1'], ['less chance of heart attact', 'more chance of heart attact'], inplace = True)\n",
    "heart.chestPain.replace(['0', '1', '2', '3'], ['typical angina', 'atypical angina', 'non-anginal pain', 'asymptomatic'], inplace = True)\n",
    "heart.exercise_induced_angina.replace(['0', '1'], ['no', 'yes'], inplace = True)\n",
    "heart.fasting_blood_sugar.replace(['0', '1'], ['false', 'true'], inplace = True)\n",
    "heart.resting_electrocardiographic.replace(['0', '1', '2'], ['normal', 'having ST-T wave abnormality', \"left ventricular hypertrophy by Estes' criteria\"], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "bORMmq5yR_Rb",
    "outputId": "e5ee14f6-bcc9-43c6-fe7c-b42d565959eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-146a5541-c4e8-4b0d-9a83-5205900eeea0\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chestPain</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>cholestoral</th>\n",
       "      <th>fasting_blood_sugar</th>\n",
       "      <th>resting_electrocardiographic</th>\n",
       "      <th>maximum_heart_rate</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <th>previous_peak</th>\n",
       "      <th>slope</th>\n",
       "      <th>number_of_vessels</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>true</td>\n",
       "      <td>normal</td>\n",
       "      <td>150</td>\n",
       "      <td>no</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>more chance of heart attact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>non-anginal pain</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>false</td>\n",
       "      <td>having ST-T wave abnormality</td>\n",
       "      <td>187</td>\n",
       "      <td>no</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>more chance of heart attact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-146a5541-c4e8-4b0d-9a83-5205900eeea0')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-146a5541-c4e8-4b0d-9a83-5205900eeea0 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-146a5541-c4e8-4b0d-9a83-5205900eeea0');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  _c0 age sex         chestPain resting_blood_pressure cholestoral  \\\n",
       "0   0  63   1      asymptomatic                    145         233   \n",
       "1   1  37   1  non-anginal pain                    130         250   \n",
       "\n",
       "  fasting_blood_sugar  resting_electrocardiographic maximum_heart_rate  \\\n",
       "0                true                        normal                150   \n",
       "1               false  having ST-T wave abnormality                187   \n",
       "\n",
       "  exercise_induced_angina previous_peak slope number_of_vessels thall  \\\n",
       "0                      no           2.3     0                 0     1   \n",
       "1                      no           3.5     0                 0     2   \n",
       "\n",
       "                        output  \n",
       "0  more chance of heart attact  \n",
       "1  more chance of heart attact  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBt-fsaKGi3N"
   },
   "outputs": [],
   "source": [
    "heart.to_csv('/content/gdrive/MyDrive/INFO607_project/heart_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "INFO607_EDA",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
